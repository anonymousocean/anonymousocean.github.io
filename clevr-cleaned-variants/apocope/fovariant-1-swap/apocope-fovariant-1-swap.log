'/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_apocope-fovariant-1-swap_scenes.json' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_val_scenes.json'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000001.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000001.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000000.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000000.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000005.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000005.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000002.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000002.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000004.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000004.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000003.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000003.png'
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000000.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000000.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000001.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000001.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000002.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000002.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000003.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000003.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000004.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000004.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000005.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000005.png
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000000.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000000.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000001.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000001.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000002.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000002.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000003.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000003.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000004.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000004.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000005.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000005.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_val_scenes.json' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/scenes/CLEVR_val_scenes.json'
INFO test_net.py:  73: Called with args:
INFO test_net.py:  74: Namespace(cfg_file='configs/baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml', clevr_comp_cat=1, dataset='clevr_original_val', load_ckpt='/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/object_detector.pt', load_detectron=None, multi_gpu_testing=False, output_dir='/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn/results/clevr_val_pretrained', range=None, set_cfgs=[], vis=False)
INFO test_net.py: 114: Testing with config:
INFO test_net.py: 115: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CLEVR': {'COMP_CAT': True},
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet50_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': True,
           'NUM_CLASSES': 49,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'MSRAFill',
           'DILATION': 1,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 28,
           'ROI_MASK_HEAD': 'mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 14,
           'ROI_XFORM_SAMPLING_RATIO': 2,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 8,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'pretrained_model/resnet50_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/vdp-tool-chain-repo/clevr-inference/scene_parse/mask_rcnn',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 0.02,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 20000, 26000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('clevr_original_val',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1333,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 1000,
          'SCALE': 800,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5}},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_CONV_BODY': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 1333,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (800,),
           'SNAPSHOT_ITERS': 20000,
           'USE_FLIPPED': False},
 'VIS': False,
 'VIS_TH': 0.9}
INFO test_engine.py: 331: loading checkpoint /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/object_detector.pt
INFO test_engine.py: 282: im_detect: range [1, 6] of 6: 1/6 1.081s + 0.004s (eta: 0:00:05)
INFO test_engine.py: 315: Wrote detections to: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn/results/clevr_val_pretrained/detections.pkl
INFO test_engine.py: 162: Total inference time: 5.851s
/home/ubuntu/vdp-tool-chain-repo/clevr-inference/scene_parse/mask_rcnn/lib/core/config.py:1046: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = AttrDict(yaml.load(f))
| processing proposals 1 / 6 images
| processing proposals 2 / 6 images
| processing proposals 3 / 6 images
| processing proposals 4 / 6 images
| processing proposals 5 / 6 images
| processing proposals 6 / 6 images
| saving object annotations to /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_val_objs_pretrained.json
| options
run_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results
dataset: clevr
load_checkpoint_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/attribute_net.pt
gpu_ids: [0]
clevr_mini_img_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_mini/images
clevr_mini_ann_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_mini_objs.json
concat_img: 1
split_id: 3500
batch_size: 50
num_workers: 4
learning_rate: 0.002
split: val
output_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results/clevr_val_scenes_parsed_pretrained.json
clevr_val_ann_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_val_objs_pretrained.json
clevr_val_img_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val
shuffle_data: 0
use_cat_label: 1
| loading checkpoint from /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/attribute_net.pt
clevr_object.py: CLEVR_val_000000.png val 0 0
clevr_object.py: CLEVR_val_000000.png val 0 1
clevr_object.py: CLEVR_val_000000.png val 0 2
clevr_object.py: CLEVR_val_000001.png val 1 3
clevr_object.py: CLEVR_val_000001.png val 1 4
clevr_object.py: CLEVR_val_000001.png val 1 5
clevr_object.py: CLEVR_val_000001.png val 1 6
clevr_object.py: CLEVR_val_000002.png val 2 7
clevr_object.py: CLEVR_val_000002.png val 2 8
clevr_object.py: CLEVR_val_000003.png val 3 9
clevr_object.py: CLEVR_val_000003.png val 3 10
clevr_object.py: CLEVR_val_000004.png val 4 11
clevr_object.py: CLEVR_val_000004.png val 4 12
clevr_object.py: CLEVR_val_000004.png val 4 13
clevr_object.py: CLEVR_val_000004.png val 4 14
clevr_object.py: CLEVR_val_000005.png val 5 15
clevr_object.py: CLEVR_val_000005.png val 5 16
clevr_object.py: CLEVR_val_000005.png val 5 17
18 / 18 objects processed
| saving annotation file to /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results/clevr_val_scenes_parsed_pretrained.json
0.json in test
THRESHOLD relate_behind objs = {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}, {'id': '0-2', 'position': [-2.8926548957824707, -0.27770331501960754, 0.6977566480636597], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}, {'id': '0-1', 'position': [2.7757503986358643, 0.28035488724708557, 0.7083861827850342], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '0-1', 'position': [2.7757503986358643, 0.28035488724708557, 0.7083861827850342], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '0-2', 'position': [-2.8926548957824707, -0.27770331501960754, 0.6977566480636597], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}
1.json in test
THRESHOLD relate_behind objs = {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
2.json in test
THRESHOLD relate_behind objs = {'id': '2-0', 'position': [1.9570459127426147, 0.10463730245828629, 0.34472864866256714], 'color': 'yellow', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '2-1', 'position': [-0.010399766266345978, -0.0005585812032222748, 0.6869317293167114], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '2-1', 'position': [-0.010399766266345978, -0.0005585812032222748, 0.6869317293167114], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '2-0', 'position': [1.9570459127426147, 0.10463730245828629, 0.34472864866256714], 'color': 'yellow', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
3.json in train
THRESHOLD relate_front objs = {'id': '3-0', 'position': [-1.4246606826782227, -0.13644741475582123, 0.3459007143974304], 'color': 'red', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '3-1', 'position': [0.7153854370117188, -0.0036228764802217484, 0.6944142580032349], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '3-1', 'position': [0.7153854370117188, -0.0036228764802217484, 0.6944142580032349], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '3-0', 'position': [-1.4246606826782227, -0.13644741475582123, 0.3459007143974304], 'color': 'red', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
4.json in train
THRESHOLD relate_behind objs = {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
5.json in train
THRESHOLD relate_behind objs = {'id': '5-0', 'position': [2.7389121055603027, 0.2974308133125305, 0.690906822681427], 'color': 'blue', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '5-2', 'position': [-2.887524366378784, -0.10492277145385742, 0.6927850246429443], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '5-0', 'position': [2.7389121055603027, 0.2974308133125305, 0.690906822681427], 'color': 'blue', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '5-2', 'position': [-2.887524366378784, -0.10492277145385742, 0.6927850246429443], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
2021-05-30 18:44:54.714053: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-05-30 18:44:54.798706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 18:44:54.799483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2021-05-30 18:44:54.799516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2021-05-30 18:44:55.128127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-30 18:44:55.128169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2021-05-30 18:44:55.128180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2021-05-30 18:44:55.128283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10769 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
Using TensorFlow backend.
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
'/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_apocope-fovariant-1-swap_scenes.json' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_val_scenes.json'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000001.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000001.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000000.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000000.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000005.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000005.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000002.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000002.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000004.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000004.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000003.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000003.png'
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000000.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000000.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000001.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000001.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000002.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000002.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000003.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000003.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000004.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000004.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000005.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000005.png
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000000.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000000.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000001.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000001.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000002.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000002.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000003.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000003.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000004.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000004.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000005.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000005.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_val_scenes.json' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/scenes/CLEVR_val_scenes.json'
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
INFO test_net.py:  73: Called with args:
INFO test_net.py:  74: Namespace(cfg_file='configs/baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml', clevr_comp_cat=1, dataset='clevr_original_val', load_ckpt='/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/object_detector.pt', load_detectron=None, multi_gpu_testing=False, output_dir='/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn/results/clevr_val_pretrained', range=None, set_cfgs=[], vis=False)
/home/ubuntu/vdp-tool-chain-repo/clevr-inference/scene_parse/mask_rcnn/lib/core/config.py:1046: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = AttrDict(yaml.load(f))
INFO test_net.py: 114: Testing with config:
INFO test_net.py: 115: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CLEVR': {'COMP_CAT': True},
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet50_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': True,
           'NUM_CLASSES': 49,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'MSRAFill',
           'DILATION': 1,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 28,
           'ROI_MASK_HEAD': 'mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 14,
           'ROI_XFORM_SAMPLING_RATIO': 2,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 8,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'pretrained_model/resnet50_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/vdp-tool-chain-repo/clevr-inference/scene_parse/mask_rcnn',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 0.02,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 20000, 26000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('clevr_original_val',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1333,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 1000,
          'SCALE': 800,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5}},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_CONV_BODY': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 1333,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (800,),
           'SNAPSHOT_ITERS': 20000,
           'USE_FLIPPED': False},
 'VIS': False,
 'VIS_TH': 0.9}
INFO test_engine.py: 331: loading checkpoint /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/object_detector.pt
INFO test_engine.py: 282: im_detect: range [1, 6] of 6: 1/6 1.126s + 0.004s (eta: 0:00:05)
INFO test_engine.py: 315: Wrote detections to: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn/results/clevr_val_pretrained/detections.pkl
INFO test_engine.py: 162: Total inference time: 5.767s
| processing proposals 1 / 6 images
| processing proposals 2 / 6 images
| processing proposals 3 / 6 images
| processing proposals 4 / 6 images
| processing proposals 5 / 6 images
| processing proposals 6 / 6 images
| saving object annotations to /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_val_objs_pretrained.json
| options
run_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results
dataset: clevr
load_checkpoint_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/attribute_net.pt
gpu_ids: [0]
clevr_mini_img_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_mini/images
clevr_mini_ann_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_mini_objs.json
concat_img: 1
split_id: 3500
batch_size: 50
num_workers: 4
learning_rate: 0.002
split: val
output_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results/clevr_val_scenes_parsed_pretrained.json
clevr_val_ann_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_val_objs_pretrained.json
clevr_val_img_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val
shuffle_data: 0
use_cat_label: 1
| loading checkpoint from /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/attribute_net.pt
clevr_object.py: CLEVR_val_000000.png val 0 0
clevr_object.py: CLEVR_val_000000.png val 0 1
clevr_object.py: CLEVR_val_000000.png val 0 2
clevr_object.py: CLEVR_val_000001.png val 1 3
clevr_object.py: CLEVR_val_000001.png val 1 4
clevr_object.py: CLEVR_val_000001.png val 1 5
clevr_object.py: CLEVR_val_000001.png val 1 6
clevr_object.py: CLEVR_val_000002.png val 2 7
clevr_object.py: CLEVR_val_000002.png val 2 8
clevr_object.py: CLEVR_val_000003.png val 3 9
clevr_object.py: CLEVR_val_000003.png val 3 10
clevr_object.py: CLEVR_val_000004.png val 4 11
clevr_object.py: CLEVR_val_000004.png val 4 12
clevr_object.py: CLEVR_val_000004.png val 4 13
clevr_object.py: CLEVR_val_000004.png val 4 14
clevr_object.py: CLEVR_val_000005.png val 5 15
clevr_object.py: CLEVR_val_000005.png val 5 16
clevr_object.py: CLEVR_val_000005.png val 5 17
18 / 18 objects processed
| saving annotation file to /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results/clevr_val_scenes_parsed_pretrained.json
0.json in test
THRESHOLD relate_behind objs = {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}, {'id': '0-2', 'position': [-2.8926548957824707, -0.27770331501960754, 0.6977566480636597], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}, {'id': '0-1', 'position': [2.7757503986358643, 0.28035488724708557, 0.7083861827850342], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '0-1', 'position': [2.7757503986358643, 0.28035488724708557, 0.7083861827850342], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '0-2', 'position': [-2.8926548957824707, -0.27770331501960754, 0.6977566480636597], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '0-0', 'position': [-0.004715226590633392, 0.042627863585948944, 0.34426599740982056], 'color': 'purple', 'material': 'rubber', 'shape': 'cube', 'size': 'small'}
1.json in test
THRESHOLD relate_behind objs = {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-0', 'position': [3.0090596675872803, 0.16992729902267456, 0.3456365764141083], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-1', 'position': [-1.4098573923110962, -0.14833807945251465, 0.3481632471084595], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-3', 'position': [-3.177731990814209, -0.26014578342437744, 0.692886471748352], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '1-2', 'position': [1.3848183155059814, -0.029925543814897537, 0.6904259324073792], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
2.json in test
THRESHOLD relate_behind objs = {'id': '2-0', 'position': [1.9570459127426147, 0.10463730245828629, 0.34472864866256714], 'color': 'yellow', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '2-1', 'position': [-0.010399766266345978, -0.0005585812032222748, 0.6869317293167114], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '2-1', 'position': [-0.010399766266345978, -0.0005585812032222748, 0.6869317293167114], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '2-0', 'position': [1.9570459127426147, 0.10463730245828629, 0.34472864866256714], 'color': 'yellow', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
3.json in train
THRESHOLD relate_front objs = {'id': '3-0', 'position': [-1.4246606826782227, -0.13644741475582123, 0.3459007143974304], 'color': 'red', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '3-1', 'position': [0.7153854370117188, -0.0036228764802217484, 0.6944142580032349], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '3-1', 'position': [0.7153854370117188, -0.0036228764802217484, 0.6944142580032349], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '3-0', 'position': [-1.4246606826782227, -0.13644741475582123, 0.3459007143974304], 'color': 'red', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
4.json in train
THRESHOLD relate_behind objs = {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-1', 'position': [-3.524855375289917, -0.34410881996154785, 0.688751757144928], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-0', 'position': [1.3482162952423096, -0.03914174064993858, 0.34402960538864136], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '4-3', 'position': [-0.7224356532096863, -0.23534059524536133, 0.6874728202819824], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '4-2', 'position': [3.127631664276123, 0.15508794784545898, 0.7050965428352356], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
5.json in train
THRESHOLD relate_behind objs = {'id': '5-0', 'position': [2.7389121055603027, 0.2974308133125305, 0.690906822681427], 'color': 'blue', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '5-2', 'position': [-2.887524366378784, -0.10492277145385742, 0.6927850246429443], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}, {'id': '5-0', 'position': [2.7389121055603027, 0.2974308133125305, 0.690906822681427], 'color': 'blue', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '5-2', 'position': [-2.887524366378784, -0.10492277145385742, 0.6927850246429443], 'color': 'yellow', 'material': 'metal', 'shape': 'sphere', 'size': 'large'}, {'id': '5-1', 'position': [-0.13622349500656128, 0.12443225830793381, 0.3419719934463501], 'color': 'purple', 'material': 'metal', 'shape': 'cube', 'size': 'small'}
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
Using TensorFlow backend.
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-06-03 07:02:55.797946: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-06-03 07:02:55.885633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-06-03 07:02:55.886419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2021-06-03 07:02:55.886445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2021-06-03 07:02:56.198028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-06-03 07:02:56.198092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2021-06-03 07:02:56.198104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2021-06-03 07:02:56.198231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10769 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
'/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_apocope-fovariant-1-swap_scenes.json' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_val_scenes.json'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000001.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000001.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000000.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000000.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000005.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000005.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000002.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000002.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000004.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000004.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/apocope-fovariant-1-swap/CLEVR_apocope-fovariant-1-swap_000003.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000003.png'
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000000.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000000.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000001.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000001.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000002.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000002.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000003.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000003.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000004.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000004.png
/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_apocope-fovariant-1-swap_000005.png renamed as /home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000005.png
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000000.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000000.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000001.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000001.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000002.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000002.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000003.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000003.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000004.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000004.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/images/val/CLEVR_val_000005.png' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val/CLEVR_val_000005.png'
'/home/ubuntu/vdp-tool-chain-repo/data/output/CLEVR_val_scenes.json' -> '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/scenes/CLEVR_val_scenes.json'
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
INFO test_net.py:  73: Called with args:
INFO test_net.py:  74: Namespace(cfg_file='configs/baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml', clevr_comp_cat=1, dataset='clevr_original_val', load_ckpt='/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/object_detector.pt', load_detectron=None, multi_gpu_testing=False, output_dir='/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn/results/clevr_val_pretrained', range=None, set_cfgs=[], vis=False)
/home/ubuntu/vdp-tool-chain-repo/clevr-inference/scene_parse/mask_rcnn/lib/core/config.py:1046: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = AttrDict(yaml.load(f))
INFO test_net.py: 114: Testing with config:
INFO test_net.py: 115: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CLEVR': {'COMP_CAT': True},
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet50_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': True,
           'NUM_CLASSES': 49,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'MSRAFill',
           'DILATION': 1,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 28,
           'ROI_MASK_HEAD': 'mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 14,
           'ROI_XFORM_SAMPLING_RATIO': 2,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 8,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'pretrained_model/resnet50_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/vdp-tool-chain-repo/clevr-inference/scene_parse/mask_rcnn',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 0.02,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 20000, 26000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('clevr_original_val',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1333,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 1000,
          'SCALE': 800,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5}},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_CONV_BODY': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 1333,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (800,),
           'SNAPSHOT_ITERS': 20000,
           'USE_FLIPPED': False},
 'VIS': False,
 'VIS_TH': 0.9}
INFO test_engine.py: 331: loading checkpoint /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/object_detector.pt
INFO test_engine.py: 282: im_detect: range [1, 6] of 6: 1/6 1.144s + 0.004s (eta: 0:00:05)
INFO test_engine.py: 315: Wrote detections to: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/mask_rcnn/results/clevr_val_pretrained/detections.pkl
INFO test_engine.py: 162: Total inference time: 5.840s
| processing proposals 1 / 6 images
| processing proposals 2 / 6 images
| processing proposals 3 / 6 images
| processing proposals 4 / 6 images
| processing proposals 5 / 6 images
| processing proposals 6 / 6 images
| saving object annotations to /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_val_objs_pretrained.json
| options
run_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results
dataset: clevr
load_checkpoint_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/attribute_net.pt
gpu_ids: [0]
clevr_mini_img_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_mini/images
clevr_mini_ann_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_mini_objs.json
concat_img: 1
split_id: 3500
batch_size: 50
num_workers: 4
learning_rate: 0.002
split: val
output_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results/clevr_val_scenes_parsed_pretrained.json
clevr_val_ann_path: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/objects/clevr_val_objs_pretrained.json
clevr_val_img_dir: /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/raw/CLEVR_v1.0/images/val
shuffle_data: 0
use_cat_label: 1
| loading checkpoint from /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/pretrained/attribute_net.pt
clevr_object.py: CLEVR_val_000000.png val 0 0
clevr_object.py: CLEVR_val_000000.png val 0 1
clevr_object.py: CLEVR_val_000000.png val 0 2
clevr_object.py: CLEVR_val_000001.png val 1 3
clevr_object.py: CLEVR_val_000001.png val 1 4
clevr_object.py: CLEVR_val_000001.png val 1 5
clevr_object.py: CLEVR_val_000001.png val 1 6
clevr_object.py: CLEVR_val_000002.png val 2 7
clevr_object.py: CLEVR_val_000002.png val 2 8
clevr_object.py: CLEVR_val_000003.png val 3 9
clevr_object.py: CLEVR_val_000003.png val 3 10
clevr_object.py: CLEVR_val_000004.png val 4 11
clevr_object.py: CLEVR_val_000004.png val 4 12
clevr_object.py: CLEVR_val_000004.png val 4 13
clevr_object.py: CLEVR_val_000004.png val 4 14
clevr_object.py: CLEVR_val_000005.png val 5 15
clevr_object.py: CLEVR_val_000005.png val 5 16
clevr_object.py: CLEVR_val_000005.png val 5 17
18 / 18 objects processed
| saving annotation file to /home/ubuntu/vdp-tool-chain-repo/data/ns-vqa-data/attr_net/results/clevr_val_scenes_parsed_pretrained.json
0.json in test
THRESHOLD relate_behind objs = {'id': '0-0', 'position': [0.06410352885723114, -0.027227796614170074, 0.3410032093524933], 'color': 'cyan', 'material': 'rubber', 'shape': 'cylinder', 'size': 'small'}, {'id': '0-2', 'position': [-2.8367373943328857, -0.10625351965427399, 0.6935093402862549], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '0-0', 'position': [0.06410352885723114, -0.027227796614170074, 0.3410032093524933], 'color': 'cyan', 'material': 'rubber', 'shape': 'cylinder', 'size': 'small'}, {'id': '0-1', 'position': [2.7976200580596924, 0.29243233799934387, 0.6923621296882629], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '0-1', 'position': [2.7976200580596924, 0.29243233799934387, 0.6923621296882629], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '0-0', 'position': [0.06410352885723114, -0.027227796614170074, 0.3410032093524933], 'color': 'cyan', 'material': 'rubber', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '0-1', 'position': [2.7976200580596924, 0.29243233799934387, 0.6923621296882629], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '0-2', 'position': [-2.8367373943328857, -0.10625351965427399, 0.6935093402862549], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '0-2', 'position': [-2.8367373943328857, -0.10625351965427399, 0.6935093402862549], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '0-0', 'position': [0.06410352885723114, -0.027227796614170074, 0.3410032093524933], 'color': 'cyan', 'material': 'rubber', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '0-2', 'position': [-2.8367373943328857, -0.10625351965427399, 0.6935093402862549], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '0-1', 'position': [2.7976200580596924, 0.29243233799934387, 0.6923621296882629], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
1.json in test
THRESHOLD relate_behind objs = {'id': '1-0', 'position': [-1.245947241783142, 0.09986019879579544, 0.34548038244247437], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '1-3', 'position': [-3.0846610069274902, -0.08556563407182693, 0.69170081615448], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '1-0', 'position': [-1.245947241783142, 0.09986019879579544, 0.34548038244247437], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '1-1', 'position': [3.27255916595459, 0.33715423941612244, 0.3428494334220886], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-0', 'position': [-1.245947241783142, 0.09986019879579544, 0.34548038244247437], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '1-2', 'position': [1.4638608694076538, 0.22803908586502075, 0.694523274898529], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '1-1', 'position': [3.27255916595459, 0.33715423941612244, 0.3428494334220886], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '1-0', 'position': [-1.245947241783142, 0.09986019879579544, 0.34548038244247437], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '1-1', 'position': [3.27255916595459, 0.33715423941612244, 0.3428494334220886], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '1-2', 'position': [1.4638608694076538, 0.22803908586502075, 0.694523274898529], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '1-2', 'position': [1.4638608694076538, 0.22803908586502075, 0.694523274898529], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '1-0', 'position': [-1.245947241783142, 0.09986019879579544, 0.34548038244247437], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '1-2', 'position': [1.4638608694076538, 0.22803908586502075, 0.694523274898529], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '1-3', 'position': [-3.0846610069274902, -0.08556563407182693, 0.69170081615448], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '1-2', 'position': [1.4638608694076538, 0.22803908586502075, 0.694523274898529], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '1-1', 'position': [3.27255916595459, 0.33715423941612244, 0.3428494334220886], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-3', 'position': [-3.0846610069274902, -0.08556563407182693, 0.69170081615448], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '1-0', 'position': [-1.245947241783142, 0.09986019879579544, 0.34548038244247437], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '1-3', 'position': [-3.0846610069274902, -0.08556563407182693, 0.69170081615448], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '1-2', 'position': [1.4638608694076538, 0.22803908586502075, 0.694523274898529], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
2.json in test
THRESHOLD relate_front objs = {'id': '2-0', 'position': [0.015979483723640442, -0.19632214307785034, 0.6931637525558472], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '2-1', 'position': [2.2105793952941895, -0.05400187522172928, 0.3455263376235962], 'color': 'gray', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '2-1', 'position': [2.2105793952941895, -0.05400187522172928, 0.3455263376235962], 'color': 'gray', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '2-0', 'position': [0.015979483723640442, -0.19632214307785034, 0.6931637525558472], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
3.json in train
THRESHOLD relate_behind objs = {'id': '3-0', 'position': [0.6136181354522705, 0.12623974680900574, 0.6948072910308838], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '3-1', 'position': [-1.5754845142364502, 0.05865313112735748, 0.341757595539093], 'color': 'yellow', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '3-1', 'position': [-1.5754845142364502, 0.05865313112735748, 0.341757595539093], 'color': 'yellow', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '3-0', 'position': [0.6136181354522705, 0.12623974680900574, 0.6948072910308838], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
4.json in train
THRESHOLD relate_behind objs = {'id': '4-0', 'position': [1.4437284469604492, 0.05396006256341934, 0.3434579372406006], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '4-1', 'position': [-3.3562333583831787, -0.305833101272583, 0.6896606087684631], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-0', 'position': [1.4437284469604492, 0.05396006256341934, 0.3434579372406006], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '4-2', 'position': [-0.5912132263183594, -0.15449276566505432, 0.6896353960037231], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-0', 'position': [1.4437284469604492, 0.05396006256341934, 0.3434579372406006], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '4-3', 'position': [3.190612554550171, 0.1899755895137787, 0.6965621113777161], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-1', 'position': [-3.3562333583831787, -0.305833101272583, 0.6896606087684631], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '4-0', 'position': [1.4437284469604492, 0.05396006256341934, 0.3434579372406006], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '4-1', 'position': [-3.3562333583831787, -0.305833101272583, 0.6896606087684631], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '4-2', 'position': [-0.5912132263183594, -0.15449276566505432, 0.6896353960037231], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-2', 'position': [-0.5912132263183594, -0.15449276566505432, 0.6896353960037231], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '4-1', 'position': [-3.3562333583831787, -0.305833101272583, 0.6896606087684631], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '4-2', 'position': [-0.5912132263183594, -0.15449276566505432, 0.6896353960037231], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '4-0', 'position': [1.4437284469604492, 0.05396006256341934, 0.3434579372406006], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_front objs = {'id': '4-2', 'position': [-0.5912132263183594, -0.15449276566505432, 0.6896353960037231], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '4-3', 'position': [3.190612554550171, 0.1899755895137787, 0.6965621113777161], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_behind objs = {'id': '4-3', 'position': [3.190612554550171, 0.1899755895137787, 0.6965621113777161], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '4-0', 'position': [1.4437284469604492, 0.05396006256341934, 0.3434579372406006], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '4-3', 'position': [3.190612554550171, 0.1899755895137787, 0.6965621113777161], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '4-2', 'position': [-0.5912132263183594, -0.15449276566505432, 0.6896353960037231], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
5.json in train
THRESHOLD relate_behind objs = {'id': '5-0', 'position': [2.749490261077881, 0.22585302591323853, 0.6888232827186584], 'color': 'blue', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '5-1', 'position': [-0.002465754747390747, 0.023391850292682648, 0.34340810775756836], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
THRESHOLD relate_behind objs = {'id': '5-1', 'position': [-0.002465754747390747, 0.023391850292682648, 0.34340810775756836], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '5-2', 'position': [-2.9025025367736816, -0.1745624542236328, 0.6930257081985474], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '5-1', 'position': [-0.002465754747390747, 0.023391850292682648, 0.34340810775756836], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}, {'id': '5-0', 'position': [2.749490261077881, 0.22585302591323853, 0.6888232827186584], 'color': 'blue', 'material': 'metal', 'shape': 'cube', 'size': 'large'}
THRESHOLD relate_front objs = {'id': '5-2', 'position': [-2.9025025367736816, -0.1745624542236328, 0.6930257081985474], 'color': 'gray', 'material': 'metal', 'shape': 'cube', 'size': 'large'}, {'id': '5-1', 'position': [-0.002465754747390747, 0.023391850292682648, 0.34340810775756836], 'color': 'cyan', 'material': 'metal', 'shape': 'cylinder', 'size': 'small'}
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
Using TensorFlow backend.
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/anaconda3/envs/deep-ranking/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-06-03 07:17:23.158856: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-06-03 07:17:23.248490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-06-03 07:17:23.249292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2021-06-03 07:17:23.249318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2021-06-03 07:17:23.559152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-06-03 07:17:23.559210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2021-06-03 07:17:23.559221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2021-06-03 07:17:23.559348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10769 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
